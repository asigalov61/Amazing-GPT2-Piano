{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Amazing-GPT2-Piano.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "opVaGMqbCOjC",
        "7rOCq8hy9Zqy",
        "SjeD4JOXAhqG"
      ],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/Amazing-GPT2-Piano/blob/master/Amazing_GPT2_Piano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_8bcBYg638e",
        "colab_type": "text"
      },
      "source": [
        "# AMAZING GPT2 PIANO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPHhn4J66-Wg",
        "colab_type": "text"
      },
      "source": [
        "MAKE YOUR OWN SOTA MUSIC AI MODEL IN UNDER 10 MINUTES :)\n",
        "\n",
        "This is a slightly modified fork of Park Soochul Google Colab Notebook from his Music-GPT2 repo https://github.com/scpark20/Music-GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RbuKWVe7U4-",
        "colab_type": "text"
      },
      "source": [
        "MAESTRO Dataset is courtesy of Google Magenta Team and it is distributed under Attribution-NonCommercial-ShareAlike 4.0 International license. \n",
        "\n",
        "So keep this in mind and respect everyone's copyright, please :)\n",
        "\n",
        "Huge thanks go out to Ravi A. for his invaluable consultations and contributions that made this Colab notebook possible :) Thank you so much, bro!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opVaGMqbCOjC",
        "colab_type": "text"
      },
      "source": [
        "# I. Environment Setup and DataSet Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcKet2jTnSz0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install all requirements/dependencies. You may have to run this section twice or trice at first run and you may have to restart the runtime/see version errors. It is normal. However, please report all other issues/critical errors on my GitHub so that I can fix it. This section may take a while to execute. Please be patient. Thank you :)\n",
        "print('3...2...1...lets go...')\n",
        "%tensorflow_version 1.x\n",
        "!pip install --upgrade tensorflow-gpu==1.14\n",
        "!pip install --upgrade tensorboard==1.15.0\n",
        "!pip install --upgrade tensorboardX\n",
        "!pip install --upgrade tensorflow-estimator==1.15.0\n",
        "!pip install --upgrade numpy\n",
        "!pip install --upgrade librosa\n",
        "!pip install --upgrade gast==0.2.2\n",
        "!pip install --upgrade tqdm\n",
        "!apt-get install --upgrade swig\n",
        "!pip install --upgrade git+https://github.com/asigalov61/python3-midi\n",
        "!pip install --upgrade pypianoroll\n",
        "!pip install --upgrade pretty-midi\n",
        "#print('Copying checkpoints and Salamander piano SoundFont (via https://sites.google.com/site/soundfonts4u) from GCS...')\n",
        "#!gsutil -q -m cp gs://magentadata/soundfonts/Yamaha-C5-Salamander-JNv5.1.sf2 /content/\n",
        "#print('Installing nice MIDI rendering code...')\n",
        "#!apt-get update -qq && apt-get install -qq libfluidsynth1 build-essential libasound2-dev libjack-dev\n",
        "#!pip install -qU pyfluidsynth\n",
        "\n",
        "#import ctypes.util\n",
        "#def proxy_find_library(lib):\n",
        "#  if lib == 'fluidsynth':\n",
        "#    return 'libfluidsynth.so.1'\n",
        "#  else:\n",
        "#    return ctypes.util.find_library(lib)\n",
        "#ctypes.util.find_library = proxy_find_library\n",
        "!nvidia-smi\n",
        "print('Success :) Everything is installed and should work fine :) Enjoy!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "revrh_vNmsW7",
        "colab_type": "text"
      },
      "source": [
        "#### Data Files/Paths Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "immog683DE2b",
        "colab_type": "text"
      },
      "source": [
        "Download and unzip Training MIDIs Dataset of your choice :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa7Ms6UHKAWS",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title (Preffered) Download and Unzip Alex Piano MIDI Dataset (~2000 MIDIs)\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-Piano-Only.zip'\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92oBN0piprsn",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Optional) Download and Unzip Google Magenta MAESTRO Piano MIDI Dataset (~1300 MIDIs)\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j /content/maestro-v2.0.0-midi.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVOP9WrlDeYY",
        "colab_type": "text"
      },
      "source": [
        "Calculate the total number of available and indexable MIDI files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I4RxGd7msW8",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calculate Number of Indexable MIDI files :)\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# Modify these paths to your own paths to MAESTRO dataset\n",
        "maestro_dir = '/content'\n",
        "\n",
        "data_dirs = ['/content']\n",
        "\n",
        "data_files = []\n",
        "for data_dir in data_dirs:\n",
        "    data_files += [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) if 'mid' or 'midi' in f] # MIDI files can have MIDI and MID extensions. Remove/comment the one you do not need/use\n",
        "\n",
        "data_files.sort()\n",
        "\n",
        "print('total midi/mid files : ', len(data_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMBZycXmsXB",
        "colab_type": "text"
      },
      "source": [
        "### Event Extract from Midi Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jZYpAZTzmsXC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Extract Events from MIDI files\n",
        "import mido\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_eventlist(data_file):\n",
        "    ON = 1\n",
        "    OFF = 0\n",
        "    CC = 2\n",
        "\n",
        "    midi = mido.MidiFile(data_file)\n",
        "\n",
        "    current_time = 0\n",
        "    eventlist = []\n",
        "    cc = False\n",
        "    for msg in midi:\n",
        "        #print(msg)\n",
        "        current_time += msg.time\n",
        "\n",
        "         # NOTE ON CASE\n",
        "        if msg.type is 'note_on' and msg.velocity > 0:\n",
        "            event = [current_time, ON, msg.note, msg.velocity]\n",
        "            eventlist.append(event)\n",
        "\n",
        "         # NOTE OFF CASE        \n",
        "        elif msg.type is 'note_off' or (msg.type is 'note_on' and msg.velocity == 0):\n",
        "            event = [current_time, OFF, msg.note, msg.velocity]\n",
        "            eventlist.append(event)\n",
        "            \n",
        "        if msg.type is 'control_change':\n",
        "            \n",
        "            if msg.control != 64:\n",
        "                continue\n",
        "            \n",
        "            if cc == False and msg.value > 0:\n",
        "                cc = True\n",
        "                event = [current_time, CC, 0, 1]\n",
        "                eventlist.append(event)\n",
        "                \n",
        "            elif cc == True and msg.value == 0:\n",
        "                cc = False\n",
        "                event = [current_time, CC, 0, 0]\n",
        "                eventlist.append(event)\n",
        "                \n",
        "    eventlist = np.array(eventlist)\n",
        "    return eventlist\n",
        "\n",
        "index = np.random.randint(0, len(data_files))\n",
        "print(index)\n",
        "eventlist = get_eventlist(data_files[index])\n",
        "print(eventlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI6VSH4WmsXK",
        "colab_type": "text"
      },
      "source": [
        "### Midifile to EventListfile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T8WAGDNdmsXM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Convert each Midifile to EventListfile\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "\n",
        "dataset_dir = 'dataset'\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "\n",
        "for i in tqdm(range(len(data_files))):\n",
        "    print(data_files[i])\n",
        "    eventlist = get_eventlist(data_files[i])\n",
        "    print(eventlist.shape)\n",
        "    \n",
        "    save_file = dataset_dir + '/' + str(i)\n",
        "    data = {'eventlist': eventlist}\n",
        "    np.savez(save_file, **data, allow_pickle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rOCq8hy9Zqy",
        "colab_type": "text"
      },
      "source": [
        "# II. Training and Generating Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-rwV6GuuU3",
        "colab_type": "text"
      },
      "source": [
        "### Data List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhCj9XyCmsXT",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create a Data List from MIDI files\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import ntpath\n",
        "\n",
        "data_dirs = ['dataset']\n",
        "\n",
        "data_files = []\n",
        "\n",
        "for data_dir in data_dirs:\n",
        "    data_files += [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) if '.npz' in f]\n",
        "print(len(data_files))\n",
        "\n",
        "data_files.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGl9MpcLwRR1",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameters Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBuEPvFvwW6q",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Setup the GPT2 Model (Hyperparameters for the model structure)\n",
        "number_of_layers = 8 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "number_of_heads = 4 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "embeding_size = 256 #@param {type:\"slider\", min:0, max:1024, step:128}\n",
        "constant_time_length = 4096 #@param {type:\"slider\", min:0, max:8192, step:128}\n",
        "IntervalDim = 100\n",
        "\n",
        "VelocityDim = 32\n",
        "VelocityOffset = IntervalDim\n",
        "\n",
        "NoteOnDim = NoteOffDim = 128\n",
        "NoteOnOffset = IntervalDim + VelocityDim\n",
        "NoteOffOffset = IntervalDim + VelocityDim + NoteOnDim\n",
        "\n",
        "CCDim = 2\n",
        "CCOffset = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim\n",
        "\n",
        "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim + CCDim # 390\n",
        "\n",
        "Time = constant_time_length\n",
        "\n",
        "EmbeddingDim = embeding_size\n",
        "\n",
        "HeadDim = 32\n",
        "Heads = number_of_heads\n",
        "ContextDim = HeadDim * Heads # 512\n",
        "\n",
        "Layers = number_of_layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-To1ss6wooF",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Set and Print Created Hyperparameters\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.training import HParams\n",
        "\n",
        "def default_hparams():\n",
        "    return HParams(\n",
        "        n_vocab=EventDim,\n",
        "        n_ctx=ContextDim,\n",
        "        n_embd=EmbeddingDim,\n",
        "        n_head=Heads,\n",
        "        n_layer=Layers,\n",
        "        n_time=Time,\n",
        "    )\n",
        "\n",
        "hparams = default_hparams()\n",
        "print(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23wnWV_swjWT",
        "colab_type": "text"
      },
      "source": [
        "### Load data from npz and converter to token sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpbE54wjwzgI",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create a token sequence and plot the results\n",
        "time_augmentation_delta = 0.15 #@param {type:\"slider\", min:0, max:1.2, step:0.01}\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "def get_data(length=Time):\n",
        "    index = np.random.randint(0, len(data_files))\n",
        "    data = np.load(data_files[index])['eventlist']\n",
        "    \n",
        "    # time augmentation\n",
        "    data[:, 0] *= np.random.uniform((1-time_augmentation_delta), (1+time_augmentation_delta))\n",
        "    \n",
        "    # absolute time to relative interval\n",
        "    data[1:, 0] = data[1:, 0] - data[:-1, 0]\n",
        "    data[0, 0] = 0\n",
        "    \n",
        "    # discretize interval into IntervalDim\n",
        "    data[:, 0] = np.clip(np.round(data[:, 0] * IntervalDim), 0, IntervalDim - 1)\n",
        "    \n",
        "    # Note augmentation\n",
        "    data[:, 2] += np.random.randint(-6, 6)\n",
        "    data[:, 2] = np.clip(data[:, 2], 0, NoteOnDim - 1)\n",
        "    \n",
        "    eventlist = []\n",
        "    for d in data:\n",
        "        # append interval\n",
        "        interval = d[0]\n",
        "        eventlist.append(interval)\n",
        "    \n",
        "        # note on case\n",
        "        if d[1] == 1:\n",
        "            velocity = (d[3] / 128) * VelocityDim + VelocityOffset\n",
        "            note = d[2] + NoteOnOffset\n",
        "            eventlist.append(velocity)\n",
        "            eventlist.append(note)\n",
        "            \n",
        "        # note off case\n",
        "        elif d[1] == 0:\n",
        "            note = d[2] + NoteOffOffset\n",
        "            eventlist.append(note)\n",
        "        # CC\n",
        "        elif d[1] == 2:\n",
        "            event = CCOffset + d[3]\n",
        "            eventlist.append(event)\n",
        "            \n",
        "    eventlist = np.array(eventlist).astype(np.int)\n",
        "    \n",
        "    if len(eventlist) > (length+1):\n",
        "        start_index = np.random.randint(0, len(eventlist) - (length+1))\n",
        "        eventlist = eventlist[start_index:start_index+(length+1)]\n",
        "        \n",
        "    # pad zeros\n",
        "    if len(eventlist) < (length+1):\n",
        "        pad = (length+1) - len(eventlist)\n",
        "        eventlist = np.pad(eventlist, (pad, 0), 'constant')\n",
        "        \n",
        "    x = eventlist[:length]\n",
        "    y = eventlist[1:length+1]\n",
        "    \n",
        "    return x, y\n",
        "    \n",
        "x, y = get_data()\n",
        "print('x shape : ', x.shape)\n",
        "print('y shape : ', y.shape)\n",
        "# print(x)\n",
        "# print(y)\n",
        "    \n",
        "    \n",
        "roll = np.zeros([len(x), EventDim])\n",
        "for t, _x in enumerate(x):\n",
        "    roll[t, _x] = 1\n",
        "\n",
        "plt.figure(figsize=[18, 6])\n",
        "librosa.display.specshow(roll.T)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHxOpCHRxD5Z",
        "colab_type": "text"
      },
      "source": [
        "### GPT-2 Model Setup and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3rKfrGUxLCr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title GPT-2 source code from https://github.com/openai/gpt-2/blob/master/src/model.py\n",
        "def shape_list(x):\n",
        "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
        "    static = x.shape.as_list()\n",
        "    dynamic = tf.shape(x)\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    x = x - tf.reduce_max(x, axis=axis, keepdims=True)\n",
        "    ex = tf.exp(x)\n",
        "    return ex / tf.reduce_sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
        "\n",
        "def norm(x, scope, *, axis=-1, epsilon=1e-5):\n",
        "    \"\"\"Normalize to mean = 0, std = 1, then do a diagonal affine transform.\"\"\"\n",
        "    with tf.variable_scope(scope):\n",
        "        n_state = x.shape[-1].value\n",
        "        g = tf.get_variable('g', [n_state], initializer=tf.constant_initializer(1))\n",
        "        b = tf.get_variable('b', [n_state], initializer=tf.constant_initializer(0))\n",
        "        u = tf.reduce_mean(x, axis=axis, keepdims=True)\n",
        "        s = tf.reduce_mean(tf.square(x-u), axis=axis, keepdims=True)\n",
        "        x = (x - u) * tf.rsqrt(s + epsilon)\n",
        "        x = x*g + b\n",
        "        return x\n",
        "\n",
        "def split_states(x, n):\n",
        "    \"\"\"Reshape the last dimension of x into [n, x.shape[-1]/n].\"\"\"\n",
        "    *start, m = shape_list(x)\n",
        "    return tf.reshape(x, start + [n, m//n])\n",
        "\n",
        "def merge_states(x):\n",
        "    \"\"\"Smash the last two dimensions of x into a single dimension.\"\"\"\n",
        "    *start, a, b = shape_list(x)\n",
        "    return tf.reshape(x, start + [a*b])\n",
        "\n",
        "def conv1d(x, scope, nf, *, w_init_stdev=0.02):\n",
        "    with tf.variable_scope(scope):\n",
        "        *start, nx = shape_list(x)\n",
        "        w = tf.get_variable('w', [1, nx, nf], initializer=tf.random_normal_initializer(stddev=w_init_stdev))\n",
        "        b = tf.get_variable('b', [nf], initializer=tf.constant_initializer(0))\n",
        "        c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n",
        "        return c\n",
        "\n",
        "def attention_mask(nd, ns, *, dtype):\n",
        "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
        "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
        "    \"\"\"\n",
        "    i = tf.range(nd)[:,None]\n",
        "    j = tf.range(ns)\n",
        "    m = i >= j - ns + nd\n",
        "    return tf.cast(m, dtype)\n",
        "\n",
        "'''\n",
        "MEMORY EFFICIENT IMPLEMENTATION OF RELATIVE POSITION-BASED ATTENTION\n",
        "(Music Transformer, Cheng-Zhi Anna Huang et al. 2018)\n",
        "'''\n",
        "def attn(x, scope, n_state, *, hparams):\n",
        "    assert x.shape.ndims == 3  # Should be [batch, sequence, features]\n",
        "    assert n_state % hparams.n_head == 0\n",
        "\n",
        "    def split_heads(x):\n",
        "        # From [batch, sequence, features] to [batch, heads, sequence, features]\n",
        "        return tf.transpose(split_states(x, hparams.n_head), [0, 2, 1, 3])\n",
        "\n",
        "    def merge_heads(x):\n",
        "        # Reverse of split_heads\n",
        "        return merge_states(tf.transpose(x, [0, 2, 1, 3]))\n",
        "\n",
        "    def mask_attn_weights(w):\n",
        "        # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
        "        _, _, nd, ns = shape_list(w)\n",
        "        b = attention_mask(nd, ns, dtype=w.dtype)\n",
        "        b = tf.reshape(b, [1, 1, nd, ns])\n",
        "        w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
        "        return w\n",
        "    \n",
        "    def relative_attn(q):\n",
        "        # q have shape [batch, heads, sequence, features]\n",
        "        batch, heads, sequence, features = shape_list(q)\n",
        "        E = tf.get_variable('E', [heads, sequence, features])\n",
        "        # [heads, batch, sequence, features]\n",
        "        q_ = tf.transpose(q, [1, 0, 2, 3])\n",
        "        # [heads, batch * sequence, features]\n",
        "        q_ = tf.reshape(q_, [heads, batch * sequence, features])\n",
        "        # [heads, batch * sequence, sequence]\n",
        "        rel = tf.matmul(q_, E, transpose_b=True)\n",
        "        # [heads, batch, sequence, sequence]\n",
        "        rel = tf.reshape(rel, [heads, batch, sequence, sequence])\n",
        "        # [heads, batch, sequence, 1+sequence]\n",
        "        rel = tf.pad(rel, ((0, 0), (0, 0), (0, 0), (1, 0)))\n",
        "        # [heads, batch, sequence+1, sequence]\n",
        "        rel = tf.reshape(rel, (heads, batch, sequence+1, sequence))\n",
        "        # [heads, batch, sequence, sequence]\n",
        "        rel = rel[:, :, 1:]\n",
        "        # [batch, heads, sequence, sequence]\n",
        "        rel = tf.transpose(rel, [1, 0, 2, 3])\n",
        "        return rel\n",
        "        \n",
        "    def multihead_attn(q, k, v):\n",
        "        # q, k, v have shape [batch, heads, sequence, features]\n",
        "        w = tf.matmul(q, k, transpose_b=True)\n",
        "        w = w + relative_attn(q)\n",
        "        w = w * tf.rsqrt(tf.cast(v.shape[-1].value, w.dtype))\n",
        "\n",
        "        w = mask_attn_weights(w)\n",
        "        w = softmax(w)\n",
        "        a = tf.matmul(w, v)\n",
        "        return a\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "        c = conv1d(x, 'c_attn', n_state*3)\n",
        "        q, k, v = map(split_heads, tf.split(c, 3, axis=2))\n",
        "        present = tf.stack([k, v], axis=1)\n",
        "\n",
        "        a = multihead_attn(q, k, v)\n",
        "        a = merge_heads(a)\n",
        "        a = conv1d(a, 'c_proj', n_state)\n",
        "        return a, present\n",
        "\n",
        "\n",
        "def mlp(x, scope, n_state, *, hparams):\n",
        "    with tf.variable_scope(scope):\n",
        "        nx = x.shape[-1].value\n",
        "        h = gelu(conv1d(x, 'c_fc', n_state))\n",
        "        h2 = conv1d(h, 'c_proj', nx)\n",
        "        return h2\n",
        "\n",
        "\n",
        "def block(x, scope, *, hparams):\n",
        "    with tf.variable_scope(scope):\n",
        "        nx = x.shape[-1].value\n",
        "        a, present = attn(norm(x, 'ln_1'), 'attn', nx, hparams=hparams)\n",
        "        x = x + a\n",
        "        m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n",
        "        x = x + m\n",
        "        return x, present\n",
        "\n",
        "def expand_tile(value, size):\n",
        "    \"\"\"Add a new axis of given size.\"\"\"\n",
        "    value = tf.convert_to_tensor(value, name='value')\n",
        "    ndims = value.shape.ndims\n",
        "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)\n",
        "\n",
        "def model(hparams, X, scope='model', reuse=False):\n",
        "    with tf.variable_scope(scope, reuse=reuse):\n",
        "        results = {}\n",
        "        batch, sequence = shape_list(X)\n",
        "\n",
        "        wte = tf.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
        "                             initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "        h = tf.gather(wte, X)\n",
        "\n",
        "        # Transformer\n",
        "        presents = []\n",
        "        for layer in range(hparams.n_layer):\n",
        "            h, present = block(h, 'h%d' % layer, hparams=hparams)\n",
        "            presents.append(present)\n",
        "        results['present'] = tf.stack(presents, axis=1)\n",
        "        h = norm(h, 'ln_f')\n",
        "\n",
        "        # Language model loss.  Do tokens <n predict token n?\n",
        "        h_flat = tf.reshape(h, [batch*sequence, hparams.n_embd])\n",
        "        logits = tf.matmul(h_flat, wte, transpose_b=True)\n",
        "        logits = tf.reshape(logits, [batch, sequence, hparams.n_vocab])\n",
        "        results['logits'] = logits\n",
        "        return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceWY7pbDxZpZ",
        "colab_type": "text"
      },
      "source": [
        "### Draw Main Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE1NUmfSxYYH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create Model's Main Graph\n",
        "hparams = default_hparams()\n",
        "print(hparams)\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
        "Y = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
        "\n",
        "X_onehot = tf.one_hot(X, axis=2, depth=hparams.n_vocab)\n",
        "\n",
        "logits = model(hparams, X)['logits']\n",
        "probs = tf.nn.softmax(logits, axis=2)\n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=logits)\n",
        "loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "#temperature = tf.Variable(1., name='temperature')\n",
        "temperature = 0\n",
        "u = tf.random.uniform(shape=tf.shape(logits[:, -1]), minval=1e-5, maxval=1.-1e-5)\n",
        "u = (logits[:, -1] - tf.log(temperature + 1e-8)) - tf.log(-tf.log(u))\n",
        "sample = tf.argmax(u, axis=1)\n",
        "\n",
        "#dist = tf.distributions.Categorical(logits=logits[:, -1])\n",
        "#sample = dist.sample()\n",
        "\n",
        "'''\n",
        "Train\n",
        "'''\n",
        "global_step = tf.Variable(0, name='global_step')\n",
        "learning_rate = tf.Variable(1e-4, name='learning_rate')\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
        "\n",
        "'''\n",
        "Session Open\n",
        "'''\n",
        "\n",
        "\n",
        "# GPU number to use\n",
        "gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "\n",
        "#config = tf.ConfigProto(device_count = {'GPU': 0})\n",
        "#sess = tf.Session(config=config)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('graph create')\n",
        "#!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0umXARBoxX-5",
        "colab_type": "text"
      },
      "source": [
        "### Load model if exist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9l-3uNDxs-S",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Load existing Checkpoint or Intialize an empty model\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.python import pywrap_tensorflow\n",
        "\n",
        "load_dir = 'save/gpt2-cc-interval100-attention2048-midi'\n",
        "save_dir = 'save/gpt2-cc-interval100-attention2048-midi'\n",
        "\n",
        "def get_variables_from_checkpoint_file(file_name):\n",
        "    variables = []\n",
        "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
        "\n",
        "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
        "    for key in sorted(var_to_shape_map):\n",
        "        variables.append((key, var_to_shape_map[key]))\n",
        "\n",
        "    return variables\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "if True:\n",
        "    restore_file = tf.train.latest_checkpoint(load_dir)\n",
        "    if restore_file is not None:\n",
        "        try:\n",
        "            saver.restore(sess, restore_file)\n",
        "            print(\"Model restored.\", restore_file)\n",
        "        except:\n",
        "            saved_variables = get_variables_from_checkpoint_file(restore_file)\n",
        "            model_variables = slim.get_variables_to_restore()\n",
        "            restore_variables = []\n",
        "            for model_variable in model_variables:\n",
        "                for saved_variable_name, saved_variable_shape in saved_variables:\n",
        "                    model_variable_name = model_variable.name.split(\":\")[0]\n",
        "                    if saved_variable_name == model_variable_name and tuple(saved_variable_shape) == model_variable.shape:\n",
        "                        restore_variables.append(model_variable)\n",
        "\n",
        "            init_saver = tf.train.Saver(restore_variables)\n",
        "            init_saver.restore(sess, restore_file)\n",
        "            print(\"Model partially restored.\")\n",
        "    else:\n",
        "        print('model not exist.')\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5t6m_sMx1rB",
        "colab_type": "text"
      },
      "source": [
        "### TensorboardX Logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ksgK4aAx2u5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title TensorboardX Logger\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "class Logger(SummaryWriter):\n",
        "    def __init__(self, logdir):\n",
        "        super(Logger, self).__init__(logdir)\n",
        "\n",
        "    def log(self, log_string, value, iteration):\n",
        "            self.add_scalar(log_string, value, iteration)\n",
        "            \n",
        "logger = Logger(save_dir)            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHlruxmx7mJ",
        "colab_type": "text"
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRtJ8rMSyC_F",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Train the Model (From Checkpoint or Scratch). Recommended number of steps to achieve good results is 40k-60k. Do not forget to adjust this number according to the number of batches.\n",
        "log_every_steps = 1000 #@param {type:\"slider\", min:0, max:1000, step:20}\n",
        "save_every_steps = 1000 #@param {type:\"slider\", min:0, max:1000, step:20}\n",
        "number_of_batches_per_step = 1 #@param {type:\"slider\", min:0, max:32, step:1}\n",
        "learning_rate_cc = 0.0001 #@param {type:\"slider\", min:0, max:0.001, step:0.000001}\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from time import sleep\n",
        "import time\n",
        "\n",
        "batch_size = number_of_batches_per_step # Works on Google P100 GPU and Colab Pro. Otherwise, use 1 or 2. Def = 1\n",
        "log_every = log_every_steps # Display logs/plot data every indicated number of steps. Def = 10\n",
        "save_every = save_every_steps # Save the trained model (checkpoint) every indicated number of steps. Def = 10\n",
        "\n",
        "while(True):\n",
        "    for _ in range(log_every_steps):\n",
        "        _inputs = []\n",
        "        _targets = []\n",
        "        for _ in range(batch_size):\n",
        "            while(True):\n",
        "                x, y = get_data(hparams.n_time)\n",
        "                if(x.shape == y.shape):\n",
        "                    break\n",
        "                 \n",
        "            _inputs.append(x)\n",
        "            _targets.append(y)\n",
        "        _inputs = np.stack(_inputs)\n",
        "        _targets = np.stack(_targets)\n",
        "        print(_inputs.shape, _targets.shape)\n",
        "        \n",
        "        _, _global_step, _loss = sess.run([train_step, global_step, loss], \n",
        "                                          feed_dict={X: _inputs, \n",
        "                                                     Y: _targets,\n",
        "                                                     learning_rate: learning_rate_cc})\n",
        "        print(_global_step, _loss)\n",
        "        \n",
        "        if _global_step % log_every == 0:\n",
        "            logger.log('loss', _loss, _global_step)\n",
        "        \n",
        "        if _global_step % save_every == 0:\n",
        "            save_path = saver.save(sess, save_dir + '/checkpoint', global_step=_global_step)\n",
        "            print(\"Model saved in path: %s\" % save_path)\n",
        "        \n",
        "    clear_output()\n",
        "    \n",
        "    _inputs_onehot, _probs = sess.run([X_onehot, probs], feed_dict={X: _inputs})\n",
        "    \n",
        "    plt.figure(figsize=[18, 4])\n",
        "    librosa.display.specshow(_inputs_onehot[0].T)\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=[18, 4])\n",
        "    librosa.display.specshow(_probs[0].T)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXq-mM-TFxFF",
        "colab_type": "text"
      },
      "source": [
        "###(Optional) Save the last checkpoint/currently loaded model from memory to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0mU0qhtlpI5",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Manual model save option from current memory\n",
        "save_path = saver.save(sess, save_dir + '/checkpoint', global_step=_global_step)\n",
        "print(\"Model saved in path: %s\" % save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVDIEKgB6TWR",
        "colab_type": "text"
      },
      "source": [
        "### Generate Output Sequence and save it to a MIDI file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwgMdlHx6sCQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title WARNING: Created/resulting Model may produce (partially) plagiarized (overfitted) output. Excercise care and respect the copyright, please :) NOTE: Number of generated tokens must be >= Time Constant Hyperparameter of the model (i.e. if time_constant=2048, number_of_tokens_to_generate must be >= 2048). You can also manipulate other variables below to further improve generated output. Only the last batch is saved and displayed.\n",
        "number_of_tokens_to_generate = 4096 #@param {type:\"slider\", min:128, max:8192, step:128}\n",
        "number_of_batches = 4 #@param {type:\"slider\", min:0, max:32, step:1}\n",
        "midi_ticks_multiplier = 5 #@param {type:\"slider\", min:0, max:64, step:1}\n",
        "priming_sequence_delta = 4032 #@param {type:\"slider\", min:0, max:8192, step:64}\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.python import pywrap_tensorflow\n",
        "\n",
        "load_dir = 'save/gpt2-cc-interval100-attention2048-midi'\n",
        "save_dir = 'save/gpt2-cc-interval100-attention2048-midi'\n",
        "\n",
        "def get_variables_from_checkpoint_file(file_name):\n",
        "    variables = []\n",
        "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
        "\n",
        "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
        "    for key in sorted(var_to_shape_map):\n",
        "        variables.append((key, var_to_shape_map[key]))\n",
        "\n",
        "    return variables\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "if True:\n",
        "    restore_file = tf.train.latest_checkpoint(load_dir)\n",
        "    if restore_file is not None:\n",
        "        try:\n",
        "            saver.restore(sess, restore_file)\n",
        "            print(\"Model restored.\", restore_file)\n",
        "        except:\n",
        "            saved_variables = get_variables_from_checkpoint_file(restore_file)\n",
        "            model_variables = slim.get_variables_to_restore()\n",
        "            restore_variables = []\n",
        "            for model_variable in model_variables:\n",
        "                for saved_variable_name, saved_variable_shape in saved_variables:\n",
        "                    model_variable_name = model_variable.name.split(\":\")[0]\n",
        "                    if saved_variable_name == model_variable_name and tuple(saved_variable_shape) == model_variable.shape:\n",
        "                        restore_variables.append(model_variable)\n",
        "\n",
        "            init_saver = tf.train.Saver(restore_variables)\n",
        "            init_saver.restore(sess, restore_file)\n",
        "            print(\"Model partially restored.\")\n",
        "    else:\n",
        "        print('model not exist.')\n",
        "\n",
        "N = number_of_tokens_to_generate # Number of steps/tokens you want to generate (for). Increasing over 2000 auto-switches Collab to CPU generation which is very slow. Def = 2048\n",
        "\n",
        "x, y = get_data(hparams.n_time)\n",
        "_inputs = np.zeros([number_of_batches, N], dtype=np.int32)\n",
        "#_inputs[:(N-128), :len(x)] = x[None, :]\n",
        "#_inputs[:, :len(x)] = x[None, :]\n",
        "_inputs[:priming_sequence_delta, :len(x)] = x[None, :]\n",
        "print(_inputs)\n",
        "print('Priming Tokens Quantity: ')\n",
        "print(len(x)-priming_sequence_delta)\n",
        "\n",
        "for i in tqdm(range(N-Time)):\n",
        "\n",
        "    _sample, _prob = sess.run([sample, probs], feed_dict={X: _inputs[:, i:i+Time]})\n",
        "    _inputs[:, i+Time] = _sample \n",
        "\n",
        "print(_inputs.shape)\n",
        "\n",
        "class Event():\n",
        "    def __init__(self, time, note, cc, on, velocity):\n",
        "        self.time = time\n",
        "        self.note = note\n",
        "        self.on = on\n",
        "        self.cc = cc\n",
        "        self.velocity = velocity\n",
        "\n",
        "    def get_event_sequence(self):\n",
        "        return [self.time, self.note, int(self.on)]\n",
        "\n",
        "class Note():\n",
        "    def __init__(self):\n",
        "        self.pitch = 0\n",
        "        self.start_time = 0\n",
        "        self.end_time = 0\n",
        "\n",
        "event_list = []\n",
        "time = 0\n",
        "event = None\n",
        "\n",
        "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim # 388\n",
        "\n",
        "for _input in _inputs[0]:\n",
        "    # interval\n",
        "    if _input < IntervalDim: \n",
        "        time += _input\n",
        "        event = Event(time, 0, False, 0, 0)\n",
        "\n",
        "    # velocity\n",
        "    elif _input < NoteOnOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.velocity = (_input - VelocityOffset) / VelocityDim * 128\n",
        "        #print('velocity : ', event.velocity)\n",
        "\n",
        "    # note on\n",
        "    elif _input < NoteOffOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "\n",
        "        event.note = _input - NoteOnOffset\n",
        "        event.on = True\n",
        "        event_list.append(event)\n",
        "        #event_list.append(Event(event.time + 100, event.note, False))\n",
        "        event = None\n",
        "\n",
        "    # note off\n",
        "    elif _input < CCOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.note = _input - NoteOffOffset\n",
        "        event.on = False\n",
        "        event_list.append(event)\n",
        "        event = None\n",
        "\n",
        "    ## CC\n",
        "    else:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.cc = True\n",
        "        on = _input - CCOffset == 1\n",
        "        event.on = on\n",
        "        #print(on)\n",
        "        event_list.append(event)\n",
        "        event = None\n",
        "\n",
        "import midi\n",
        "# Instantiate a MIDI Pattern (contains a list of tracks)\n",
        "pattern = midi.Pattern()\n",
        "# Instantiate a MIDI Track (contains a list of MIDI events)\n",
        "track = midi.Track()\n",
        "# Append the track to the pattern\n",
        "pattern.append(track)\n",
        "\n",
        "prev_time = 0\n",
        "pitches = [None for _ in range(128)]\n",
        "for event in event_list:\n",
        "    tick = (event.time - prev_time) * midi_ticks_multiplier\n",
        "    prev_time = event.time\n",
        "\n",
        "    # case NOTE:\n",
        "    if not event.cc:\n",
        "        if event.on:\n",
        "            if pitches[event.note] is not None:\n",
        "                # Instantiate a MIDI note off event, append it to the track\n",
        "                off = midi.NoteOffEvent(tick=0, pitch=event.note)\n",
        "                track.append(off)\n",
        "                pitches[event.note] = None\n",
        "\n",
        "            # Instantiate a MIDI note on event, append it to the track\n",
        "            on = midi.NoteOnEvent(tick=tick, velocity=int(event.velocity), pitch=event.note)\n",
        "            track.append(on)\n",
        "            pitches[event.note] = prev_time\n",
        "        else:\n",
        "            # Instantiate a MIDI note off event, append it to the track\n",
        "            off = midi.NoteOffEvent(tick=tick, pitch=event.note)\n",
        "            track.append(off)\n",
        "            pitches[event.note] = None\n",
        "\n",
        "    # case CC:\n",
        "    elif event.cc:\n",
        "        if event.on:\n",
        "            cc = midi.ControlChangeEvent(tick=tick, control=64, value=64)\n",
        "        else:\n",
        "            cc = midi.ControlChangeEvent(tick=tick, control=64, value=0)\n",
        "\n",
        "        track.append(cc)\n",
        "\n",
        "    for pitch in range(128):\n",
        "        if pitches[pitch] is not None and pitches[pitch] + 100 < prev_time:\n",
        "            #print('here')\n",
        "            off = midi.NoteOffEvent(tick=0, pitch=pitch)\n",
        "            track.append(off)\n",
        "            pitches[pitch] = None\n",
        "\n",
        "\n",
        "# Add the end of track event, append it to the track\n",
        "eot = midi.EndOfTrackEvent(tick=1)\n",
        "track.append(eot)\n",
        "# Print out the pattern\n",
        "#print(pattern)\n",
        "# Save the pattern to disk\n",
        "midi.write_midifile(\"output_file.mid\", pattern)\n",
        "\n",
        "print('Successfully exported the output to output_file.mid')\n",
        "print('Downloading output_file.mid')\n",
        "from google.colab import files\n",
        "files.download('/content/output_file.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjeD4JOXAhqG",
        "colab_type": "text"
      },
      "source": [
        "# III. Plot and Graph the Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiFahumhwqtZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot/Graph the Output and Render Output for listening (WAV)\n",
        "graphs_length_inches = 20 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 8 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "rendered_wav_graph_height = 3 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "# make the ticks absolute value\n",
        "pattern.make_ticks_abs()\n",
        "#print(pattern)\n",
        "\n",
        "# create a note class\n",
        "class Note:\n",
        "    def __init__(self, pitch, start_time):\n",
        "        self.pitch = pitch\n",
        "        self.start_time = start_time\n",
        "        self.end_time = None\n",
        "        \n",
        "    def __str__(self):\n",
        "        return str(self.pitch) + ' ' + str(self.start_time) + ' ' + str(self.end_time)\n",
        "\n",
        "# creating a sorted notelist\n",
        "time_unit = pattern.resolution / 4\n",
        "\n",
        "notelist = []\n",
        "notes = [None for _ in range(128)]\n",
        "for track in pattern:\n",
        "    for event in track:\n",
        "        if event.name == 'Note On':\n",
        "            pitch = event.get_pitch()\n",
        "            start_time = round(event.tick / time_unit)\n",
        "            note = Note(pitch, start_time)\n",
        "            notes[pitch] = note\n",
        "        \n",
        "        elif event.name == 'Note Off':\n",
        "            pitch = event.get_pitch()\n",
        "            note = notes[pitch]\n",
        "            if note is not None:\n",
        "                note.end_time = round(event.tick / time_unit)\n",
        "                notelist.append(note)\n",
        "                notes[pitch] = None\n",
        "\n",
        "# Sort notelist by order of start_time and pitch\n",
        "notelist = sorted(notelist, key=lambda note: (note.start_time, note.pitch))\n",
        "                \n",
        "#for note in notelist:\n",
        "#    print(note)\n",
        "\n",
        "# creating empty pianoroll\n",
        "import numpy as np\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "length = notelist[-1].end_time\n",
        "roll = np.zeros([int(length), 128])\n",
        "\n",
        "track = Track(pianoroll=roll, program=0, is_drum=False, name='track')\n",
        "\n",
        "#fig, ax = track.plot()\n",
        "#fig.set_size_inches(18, 5)\n",
        "#plt.show()\n",
        "\n",
        "# Plot the output\n",
        "\n",
        "for note in notelist:\n",
        "    pitch = note.pitch    \n",
        "    start_time = int(note.start_time)\n",
        "    end_time = int(note.end_time)\n",
        "    roll[start_time:end_time, pitch] = 1\n",
        "\n",
        "track = Track(pianoroll=roll, program=0, is_drum=False, name='track')\n",
        "\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.show()\n",
        "\n",
        "# Generate rendering (WAV)\n",
        "\n",
        "import pypianoroll as ppr\n",
        "import pretty_midi\n",
        "\n",
        "pm = ppr.Multitrack(tracks=[ppr.Track(roll)]).to_pretty_midi(20)\n",
        "#audio = pm.fluidsynth()\n",
        "audio = pm.synthesize()\n",
        "#print(audio.shape)\n",
        "\n",
        "plt.figure(figsize=[graphs_length_inches, rendered_wav_graph_height])\n",
        "plt.plot(audio)\n",
        "plt.show()\n",
        "\n",
        "#import IPython.display as ipd\n",
        "#ipd.Audio(audio, rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqMikmVMtTwh",
        "colab_type": "text"
      },
      "source": [
        "###Save your model to your Google Drive directly as it is very fast :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcrTq7tmC97p",
        "colab_type": "code",
        "colab": {},
        "cellView": "form"
      },
      "source": [
        "#@title Standard Google Drive connect code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}