{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.5"
    },
    "colab": {
      "name": "Amazing-GPT2-Piano.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "Hq-rwV6GuuU3",
        "23wnWV_swjWT",
        "XHxOpCHRxD5Z"
      ],
      "toc_visible": true,
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asigalov61/Amazing-GPT2-Piano/blob/master/Amazing_GPT2_Piano.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k_8bcBYg638e",
        "colab_type": "text"
      },
      "source": [
        "# AMAZING GPT2 PIANO"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPHhn4J66-Wg",
        "colab_type": "text"
      },
      "source": [
        "MAKE YOUR OWN SOTA MUSIC AI MODEL IN UNDER 10 MINUTES :)\n",
        "\n",
        "This is a slightly modified fork of Park Soochul Google Colab Notebook from his Music-GPT2 repo https://github.com/scpark20/Music-GPT-2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9RbuKWVe7U4-",
        "colab_type": "text"
      },
      "source": [
        "MAESTRO Dataset is courtesy of Google Magenta Team and it is distributed under Attribution-NonCommercial-ShareAlike 4.0 International license. \n",
        "\n",
        "So keep this in mind and respect everyone's copyright, please :)\n",
        "\n",
        "Huge thanks go out to Ravi A. for his invaluable consultations and contributions that made this Colab notebook possible :) Thank you so much, bro!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "opVaGMqbCOjC",
        "colab_type": "text"
      },
      "source": [
        "# I. Environment Setup and DataSet Prep"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcKet2jTnSz0",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Install all requirements/dependencies. You may have to run this section twice or trice at first run and you may have to restart the runtime/see version errors. It is normal. However, please report all other issues/critical errors on my GitHub so that I can fix it. This section may take a while to execute. Please be patient. Thank you :)\n",
        "print('3...2...1...lets go...')\n",
        "%tensorflow_version 1.x\n",
        "!pip install tensorflow-gpu==1.15.2\n",
        "!pip install tensorboardX\n",
        "!pip install numpy\n",
        "!pip install librosa\n",
        "!pip install gast\n",
        "!pip install tqdm\n",
        "!apt-get install swig\n",
        "!pip install git+https://github.com/asigalov61/python3-midi\n",
        "!pip install pypianoroll\n",
        "!pip install pretty-midi\n",
        "\n",
        "!nvidia-smi\n",
        "print('Success :) Everything is installed and should work fine :) Enjoy!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "revrh_vNmsW7",
        "colab_type": "text"
      },
      "source": [
        "#### Data Files/Paths Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "immog683DE2b",
        "colab_type": "text"
      },
      "source": [
        "Download and unzip Training MIDIs Dataset of your choice :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qa7Ms6UHKAWS",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Preffered) Download and Unzip Alex Piano MIDI Dataset (~2000 MIDIs). Original 430 MIDIs.\n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-Piano-Only.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwC3Ag4-fuq-",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Best Choice/Works best stand-alone) Alex Piano Only Drafts Original 1500 MIDIs \n",
        "!wget 'https://github.com/asigalov61/AlexMIDIDataSet/raw/master/AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'\n",
        "!unzip -j 'AlexMIDIDataSet-CC-BY-NC-SA-All-Drafts-Piano-Only.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92oBN0piprsn",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title (Optional) Download and Unzip Google Magenta MAESTRO Piano MIDI Dataset (~1300 MIDIs)\n",
        "!wget 'https://storage.googleapis.com/magentadata/datasets/maestro/v2.0.0/maestro-v2.0.0-midi.zip'\n",
        "!unzip -j /content/maestro-v2.0.0-midi.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLZPsSZhTuiI",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Download Pre-Trained Model Based on Alex Piano Only Drafts DataSet. The model was trained for ~30k steps with 1.32 resulting FLoss. NOTE: You must Download and Unzip at least 1 dataset or at least 1 MIDI file to the root folder of Colab for Checkpoint to load and you must run all the fields below even if you do not intend to train the model yourself.\n",
        "!wget 'https://amazinggpt2piano.s3-us-west-1.amazonaws.com/gpt2-cc-interval100-attention4096-floss1.32-29277-midi.zip'\n",
        "!unzip '/content/gpt2-cc-interval100-attention4096-floss1.32-29277-midi.zip'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DjqZ-3jdaUCx",
        "colab_type": "text"
      },
      "source": [
        "#DO NOT FORGET TO DELETE ALL ZIP FILES BEFORE RUNNING THE SECTIONS BELOW TO AVOID ERRORS/HALTS."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVOP9WrlDeYY",
        "colab_type": "text"
      },
      "source": [
        "Calculate the total number of available and indexable MIDI files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9I4RxGd7msW8",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Calculate Number of Indexable MIDI files :)\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "\n",
        "# Modify these paths to your own paths to MAESTRO dataset\n",
        "maestro_dir = '/content'\n",
        "\n",
        "data_dirs = ['/content']\n",
        "\n",
        "data_files = []\n",
        "for data_dir in data_dirs:\n",
        "    data_files += [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) if 'mid' or 'midi' in f] # MIDI files can have MIDI and MID extensions. Remove/comment the one you do not need/use\n",
        "\n",
        "data_files.sort()\n",
        "\n",
        "print('total midi/mid files : ', len(data_files))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TuMBZycXmsXB",
        "colab_type": "text"
      },
      "source": [
        "### Event Extract from Midi Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "jZYpAZTzmsXC",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Extract Events from MIDI files\n",
        "import mido\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def get_eventlist(data_file):\n",
        "    ON = 1\n",
        "    OFF = 0\n",
        "    CC = 2\n",
        "\n",
        "    midi = mido.MidiFile(data_file)\n",
        "\n",
        "    current_time = 0\n",
        "    eventlist = []\n",
        "    cc = False\n",
        "    for msg in midi:\n",
        "        #print(msg)\n",
        "        current_time += msg.time\n",
        "\n",
        "         # NOTE ON CASE\n",
        "        if msg.type is 'note_on' and msg.velocity > 0:\n",
        "            event = [current_time, ON, msg.note, msg.velocity]\n",
        "            eventlist.append(event)\n",
        "\n",
        "         # NOTE OFF CASE        \n",
        "        elif msg.type is 'note_off' or (msg.type is 'note_on' and msg.velocity == 0):\n",
        "            event = [current_time, OFF, msg.note, msg.velocity]\n",
        "            eventlist.append(event)\n",
        "\n",
        "\n",
        "            \n",
        "        if msg.type is 'control_change':\n",
        "            \n",
        "            if msg.control != 64:\n",
        "                continue\n",
        "            \n",
        "            if cc == False and msg.value > 0:\n",
        "                cc = True\n",
        "                event = [current_time, CC, 0, 1]\n",
        "                eventlist.append(event)\n",
        "                \n",
        "            elif cc == True and msg.value == 0:\n",
        "                cc = False\n",
        "                event = [current_time, CC, 0, 0]\n",
        "                eventlist.append(event)\n",
        "                \n",
        "    eventlist = np.array(eventlist)\n",
        "    return eventlist\n",
        "\n",
        "index = np.random.randint(0, len(data_files))\n",
        "print(index)\n",
        "eventlist = get_eventlist(data_files[index])\n",
        "print(eventlist)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fI6VSH4WmsXK",
        "colab_type": "text"
      },
      "source": [
        "### Midifile to EventListfile"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "T8WAGDNdmsXM",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Convert each Midifile to EventListfile\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import os\n",
        "\n",
        "dataset_dir = 'dataset'\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "    os.makedirs(dataset_dir)\n",
        "\n",
        "for i in tqdm(range(len(data_files))):\n",
        "    print(data_files[i])\n",
        "    eventlist = get_eventlist(data_files[i])\n",
        "    print(eventlist.shape)\n",
        "    \n",
        "    save_file = dataset_dir + '/' + str(i)\n",
        "    data = {'eventlist': eventlist}\n",
        "    np.savez(save_file, **data, allow_pickle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7rOCq8hy9Zqy",
        "colab_type": "text"
      },
      "source": [
        "# II. Training and Generating Output"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hq-rwV6GuuU3",
        "colab_type": "text"
      },
      "source": [
        "### Data List"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WhCj9XyCmsXT",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create a Data List from MIDI files\n",
        "import os\n",
        "from os import listdir\n",
        "from os.path import isfile, join\n",
        "import ntpath\n",
        "\n",
        "data_dirs = ['dataset']\n",
        "\n",
        "data_files = []\n",
        "\n",
        "for data_dir in data_dirs:\n",
        "    data_files += [join(data_dir, f) for f in listdir(data_dir) if isfile(join(data_dir, f)) if '.npz' in f]\n",
        "print(len(data_files))\n",
        "\n",
        "data_files.sort()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WGl9MpcLwRR1",
        "colab_type": "text"
      },
      "source": [
        "### Hyperparameters Setting"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CBuEPvFvwW6q",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Setup the GPT2 Model (Hyperparameters for the model structure)\n",
        "number_of_layers = 12 #@param {type:\"slider\", min:1, max:16, step:1}\n",
        "number_of_heads = 16 #@param {type:\"slider\", min:1, max:32, step:1}\n",
        "embeding_size = 128 #@param {type:\"slider\", min:0, max:1024, step:128}\n",
        "constant_time_length = 1024 #@param {type:\"slider\", min:0, max:8192, step:128}\n",
        "IntervalDim = 100\n",
        "\n",
        "VelocityDim = 32\n",
        "VelocityOffset = IntervalDim\n",
        "\n",
        "NoteOnDim = NoteOffDim = 128\n",
        "NoteOnOffset = IntervalDim + VelocityDim\n",
        "NoteOffOffset = IntervalDim + VelocityDim + NoteOnDim\n",
        "\n",
        "CCDim = 2\n",
        "CCOffset = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim\n",
        "\n",
        "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim + CCDim # 390\n",
        "\n",
        "Time = constant_time_length\n",
        "\n",
        "EmbeddingDim = embeding_size\n",
        "\n",
        "HeadDim = 32\n",
        "Heads = number_of_heads\n",
        "ContextDim = HeadDim * Heads # 512\n",
        "\n",
        "Layers = number_of_layers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p-To1ss6wooF",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Set and Print Created Hyperparameters\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.contrib.training import HParams\n",
        "\n",
        "def default_hparams():\n",
        "    return HParams(\n",
        "        n_vocab=EventDim,\n",
        "        n_ctx=ContextDim,\n",
        "        n_embd=EmbeddingDim,\n",
        "        n_head=Heads,\n",
        "        n_layer=Layers,\n",
        "        n_time=Time,\n",
        "    )\n",
        "\n",
        "hparams = default_hparams()\n",
        "print(hparams)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "23wnWV_swjWT",
        "colab_type": "text"
      },
      "source": [
        "### Load data from npz and converter to token sequence"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KpbE54wjwzgI",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "#@title Create a token sequence and plot the results\n",
        "time_augmentation_delta = 0 #@param {type:\"slider\", min:0, max:1.2, step:0.01}\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "\n",
        "def get_data(length=Time):\n",
        "    index = np.random.randint(0, len(data_files))\n",
        "    data = np.load(data_files[index])['eventlist']  \n",
        "    # time augmentation\n",
        "    data[:, 0] *= np.random.uniform((1-time_augmentation_delta), (1+time_augmentation_delta))\n",
        "    \n",
        "    # absolute time to relative interval\n",
        "    data[1:, 0] = data[1:, 0] - data[:-1, 0]\n",
        "    data[0, 0] = 0\n",
        "    \n",
        "    # discretize interval into IntervalDim\n",
        "    data[:, 0] = np.clip(np.round(data[:, 0] * IntervalDim), 0, IntervalDim - 1)\n",
        "    \n",
        "    # Note augmentation\n",
        "    data[:, 2] += np.random.randint(-6, 6)\n",
        "    data[:, 2] = np.clip(data[:, 2], 0, NoteOnDim - 1)\n",
        "    \n",
        "    eventlist = []\n",
        "    for d in data:\n",
        "        # append interval\n",
        "        interval = d[0]\n",
        "        eventlist.append(interval)\n",
        "    \n",
        "        # note on case\n",
        "        if d[1] == 1:\n",
        "            velocity = (d[3] / 128) * VelocityDim + VelocityOffset\n",
        "            note = d[2] + NoteOnOffset\n",
        "            eventlist.append(velocity)\n",
        "            eventlist.append(note)\n",
        "            \n",
        "        # note off case\n",
        "        elif d[1] == 0:\n",
        "            note = d[2] + NoteOffOffset\n",
        "            eventlist.append(note)\n",
        "        # CC\n",
        "        elif d[1] == 2:\n",
        "            event = CCOffset + d[3]\n",
        "            eventlist.append(event)\n",
        "            \n",
        "    eventlist = np.array(eventlist).astype(np.int)\n",
        "    \n",
        "    if len(eventlist) > (length+1):\n",
        "        start_index = np.random.randint(0, len(eventlist) - (length+1))\n",
        "        eventlist = eventlist[start_index:start_index+(length+1)]\n",
        "        \n",
        "    # pad zeros\n",
        "    if len(eventlist) < (length+1):\n",
        "        pad = (length+1) - len(eventlist)\n",
        "        eventlist = np.pad(eventlist, (pad, 0), 'constant')\n",
        "        \n",
        "    x = eventlist[:length]\n",
        "    y = eventlist[1:length+1]\n",
        "    \n",
        "    return x, y\n",
        "    \n",
        "x, y = get_data()\n",
        "print('x shape : ', x.shape)\n",
        "print('y shape : ', y.shape)\n",
        "# print(x)\n",
        "# print(y)\n",
        "    \n",
        "    \n",
        "roll = np.zeros([len(x), EventDim])\n",
        "for t, _x in enumerate(x):\n",
        "    roll[t, _x] = 1\n",
        "\n",
        "plt.figure(figsize=[18, 6])\n",
        "librosa.display.specshow(roll.T)\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHxOpCHRxD5Z",
        "colab_type": "text"
      },
      "source": [
        "### GPT-2 Model Setup and Initialization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O3rKfrGUxLCr",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title GPT-2 source code from https://github.com/openai/gpt-2/blob/master/src/model.py\n",
        "def shape_list(x):\n",
        "    \"\"\"Deal with dynamic shape in tensorflow cleanly.\"\"\"\n",
        "    static = x.shape.as_list()\n",
        "    dynamic = tf.shape(x)\n",
        "    return [dynamic[i] if s is None else s for i, s in enumerate(static)]\n",
        "\n",
        "def softmax(x, axis=-1):\n",
        "    x = x - tf.reduce_max(x, axis=axis, keepdims=True)\n",
        "    ex = tf.exp(x)\n",
        "    return ex / tf.reduce_sum(ex, axis=axis, keepdims=True)\n",
        "\n",
        "def gelu(x):\n",
        "    return 0.5*x*(1+tf.tanh(np.sqrt(2/np.pi)*(x+0.044715*tf.pow(x, 3))))\n",
        "\n",
        "def norm(x, scope, *, axis=-1, epsilon=1e-5):\n",
        "    \"\"\"Normalize to mean = 0, std = 1, then do a diagonal affine transform.\"\"\"\n",
        "    with tf.variable_scope(scope):\n",
        "        n_state = x.shape[-1].value\n",
        "        g = tf.get_variable('g', [n_state], initializer=tf.constant_initializer(1))\n",
        "        b = tf.get_variable('b', [n_state], initializer=tf.constant_initializer(0))\n",
        "        u = tf.reduce_mean(x, axis=axis, keepdims=True)\n",
        "        s = tf.reduce_mean(tf.square(x-u), axis=axis, keepdims=True)\n",
        "        x = (x - u) * tf.rsqrt(s + epsilon)\n",
        "        x = x*g + b\n",
        "        return x\n",
        "\n",
        "def split_states(x, n):\n",
        "    \"\"\"Reshape the last dimension of x into [n, x.shape[-1]/n].\"\"\"\n",
        "    *start, m = shape_list(x)\n",
        "    return tf.reshape(x, start + [n, m//n])\n",
        "\n",
        "def merge_states(x):\n",
        "    \"\"\"Smash the last two dimensions of x into a single dimension.\"\"\"\n",
        "    *start, a, b = shape_list(x)\n",
        "    return tf.reshape(x, start + [a*b])\n",
        "\n",
        "def conv1d(x, scope, nf, *, w_init_stdev=0.02):\n",
        "    with tf.variable_scope(scope):\n",
        "        *start, nx = shape_list(x)\n",
        "        w = tf.get_variable('w', [1, nx, nf], initializer=tf.random_normal_initializer(stddev=w_init_stdev))\n",
        "        b = tf.get_variable('b', [nf], initializer=tf.constant_initializer(0))\n",
        "        c = tf.reshape(tf.matmul(tf.reshape(x, [-1, nx]), tf.reshape(w, [-1, nf]))+b, start+[nf])\n",
        "        return c\n",
        "\n",
        "def attention_mask(nd, ns, *, dtype):\n",
        "    \"\"\"1's in the lower triangle, counting from the lower right corner.\n",
        "    Same as tf.matrix_band_part(tf.ones([nd, ns]), -1, ns-nd), but doesn't produce garbage on TPUs.\n",
        "    \"\"\"\n",
        "    i = tf.range(nd)[:,None]\n",
        "    j = tf.range(ns)\n",
        "    m = i >= j - ns + nd\n",
        "    return tf.cast(m, dtype)\n",
        "\n",
        "'''\n",
        "MEMORY EFFICIENT IMPLEMENTATION OF RELATIVE POSITION-BASED ATTENTION\n",
        "(Music Transformer, Cheng-Zhi Anna Huang et al. 2018)\n",
        "'''\n",
        "def attn(x, scope, n_state, *, hparams):\n",
        "    assert x.shape.ndims == 3  # Should be [batch, sequence, features]\n",
        "    assert n_state % hparams.n_head == 0\n",
        "\n",
        "    def split_heads(x):\n",
        "        # From [batch, sequence, features] to [batch, heads, sequence, features]\n",
        "        return tf.transpose(split_states(x, hparams.n_head), [0, 2, 1, 3])\n",
        "\n",
        "    def merge_heads(x):\n",
        "        # Reverse of split_heads\n",
        "        return merge_states(tf.transpose(x, [0, 2, 1, 3]))\n",
        "\n",
        "    def mask_attn_weights(w):\n",
        "        # w has shape [batch, heads, dst_sequence, src_sequence], where information flows from src to dst.\n",
        "        _, _, nd, ns = shape_list(w)\n",
        "        b = attention_mask(nd, ns, dtype=w.dtype)\n",
        "        b = tf.reshape(b, [1, 1, nd, ns])\n",
        "        w = w*b - tf.cast(1e10, w.dtype)*(1-b)\n",
        "        return w\n",
        "    \n",
        "    def relative_attn(q):\n",
        "        # q have shape [batch, heads, sequence, features]\n",
        "        batch, heads, sequence, features = shape_list(q)\n",
        "        E = tf.get_variable('E', [heads, sequence, features])\n",
        "        # [heads, batch, sequence, features]\n",
        "        q_ = tf.transpose(q, [1, 0, 2, 3])\n",
        "        # [heads, batch * sequence, features]\n",
        "        q_ = tf.reshape(q_, [heads, batch * sequence, features])\n",
        "        # [heads, batch * sequence, sequence]\n",
        "        rel = tf.matmul(q_, E, transpose_b=True)\n",
        "        # [heads, batch, sequence, sequence]\n",
        "        rel = tf.reshape(rel, [heads, batch, sequence, sequence])\n",
        "        # [heads, batch, sequence, 1+sequence]\n",
        "        rel = tf.pad(rel, ((0, 0), (0, 0), (0, 0), (1, 0)))\n",
        "        # [heads, batch, sequence+1, sequence]\n",
        "        rel = tf.reshape(rel, (heads, batch, sequence+1, sequence))\n",
        "        # [heads, batch, sequence, sequence]\n",
        "        rel = rel[:, :, 1:]\n",
        "        # [batch, heads, sequence, sequence]\n",
        "        rel = tf.transpose(rel, [1, 0, 2, 3])\n",
        "        return rel\n",
        "        \n",
        "    def multihead_attn(q, k, v):\n",
        "        # q, k, v have shape [batch, heads, sequence, features]\n",
        "        w = tf.matmul(q, k, transpose_b=True)\n",
        "        w = w + relative_attn(q)\n",
        "        w = w * tf.rsqrt(tf.cast(v.shape[-1].value, w.dtype))\n",
        "\n",
        "        w = mask_attn_weights(w)\n",
        "        w = softmax(w)\n",
        "        a = tf.matmul(w, v)\n",
        "        return a\n",
        "\n",
        "    with tf.variable_scope(scope):\n",
        "        c = conv1d(x, 'c_attn', n_state*3)\n",
        "        q, k, v = map(split_heads, tf.split(c, 3, axis=2))\n",
        "        present = tf.stack([k, v], axis=1)\n",
        "\n",
        "        a = multihead_attn(q, k, v)\n",
        "        a = merge_heads(a)\n",
        "        a = conv1d(a, 'c_proj', n_state)\n",
        "        return a, present\n",
        "\n",
        "\n",
        "def mlp(x, scope, n_state, *, hparams):\n",
        "    with tf.variable_scope(scope):\n",
        "        nx = x.shape[-1].value\n",
        "        h = gelu(conv1d(x, 'c_fc', n_state))\n",
        "        h2 = conv1d(h, 'c_proj', nx)\n",
        "        return h2\n",
        "\n",
        "\n",
        "def block(x, scope, *, hparams):\n",
        "    with tf.variable_scope(scope):\n",
        "        nx = x.shape[-1].value\n",
        "        a, present = attn(norm(x, 'ln_1'), 'attn', nx, hparams=hparams)\n",
        "        x = x + a\n",
        "        m = mlp(norm(x, 'ln_2'), 'mlp', nx*4, hparams=hparams)\n",
        "        x = x + m\n",
        "        return x, present\n",
        "\n",
        "def expand_tile(value, size):\n",
        "    \"\"\"Add a new axis of given size.\"\"\"\n",
        "    value = tf.convert_to_tensor(value, name='value')\n",
        "    ndims = value.shape.ndims\n",
        "    return tf.tile(tf.expand_dims(value, axis=0), [size] + [1]*ndims)\n",
        "\n",
        "def model(hparams, X, scope='model', reuse=False):\n",
        "    with tf.variable_scope(scope, reuse=reuse):\n",
        "        results = {}\n",
        "        batch, sequence = shape_list(X)\n",
        "\n",
        "        wte = tf.get_variable('wte', [hparams.n_vocab, hparams.n_embd],\n",
        "                             initializer=tf.random_normal_initializer(stddev=0.02))\n",
        "        h = tf.gather(wte, X)\n",
        "\n",
        "        # Transformer\n",
        "        presents = []\n",
        "        for layer in range(hparams.n_layer):\n",
        "            h, present = block(h, 'h%d' % layer, hparams=hparams)\n",
        "            presents.append(present)\n",
        "        results['present'] = tf.stack(presents, axis=1)\n",
        "        h = norm(h, 'ln_f')\n",
        "\n",
        "        # Language model loss.  Do tokens <n predict token n?\n",
        "        h_flat = tf.reshape(h, [batch*sequence, hparams.n_embd])\n",
        "        logits = tf.matmul(h_flat, wte, transpose_b=True)\n",
        "        logits = tf.reshape(logits, [batch, sequence, hparams.n_vocab])\n",
        "        results['logits'] = logits\n",
        "        return results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ceWY7pbDxZpZ",
        "colab_type": "text"
      },
      "source": [
        "### Draw Main Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QE1NUmfSxYYH",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Create Model's Main Graph\n",
        "hparams = default_hparams()\n",
        "print(hparams)\n",
        "\n",
        "\n",
        "tf.reset_default_graph()\n",
        "\n",
        "X = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
        "Y = tf.placeholder(tf.int32, [None, hparams.n_time])\n",
        "\n",
        "X_onehot = tf.one_hot(X, axis=2, depth=hparams.n_vocab)\n",
        "\n",
        "logits = model(hparams, X)['logits']\n",
        "probs = tf.nn.softmax(logits, axis=2)\n",
        "cross_entropy = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=Y, logits=logits)\n",
        "loss = tf.reduce_mean(cross_entropy)\n",
        "\n",
        "#temperature = tf.Variable(1., name='temperature')\n",
        "temperature = 0\n",
        "u = tf.random.uniform(shape=tf.shape(logits[:, -1]), minval=1e-5, maxval=1.-1e-5)\n",
        "u = (logits[:, -1] - tf.log(temperature + 1e-8)) - tf.log(-tf.log(u))\n",
        "sample = tf.argmax(u, axis=1)\n",
        "\n",
        "#dist = tf.distributions.Categorical(logits=logits[:, -1])\n",
        "#sample = dist.sample()\n",
        "\n",
        "'''\n",
        "Train\n",
        "'''\n",
        "global_step = tf.Variable(0, name='global_step')\n",
        "learning_rate = tf.Variable(1e-4, name='learning_rate')\n",
        "train_step = tf.train.AdamOptimizer(learning_rate).minimize(loss, global_step)\n",
        "\n",
        "'''\n",
        "Session Open\n",
        "'''\n",
        "\n",
        "\n",
        "# GPU number to use\n",
        "gpu_options = tf.GPUOptions(visible_device_list=\"0\")\n",
        "sess = tf.Session(config=tf.ConfigProto(gpu_options=gpu_options))\n",
        "\n",
        "#config = tf.ConfigProto(device_count = {'GPU': 0})\n",
        "#sess = tf.Session(config=config)\n",
        "\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "print('graph create')\n",
        "#!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0umXARBoxX-5",
        "colab_type": "text"
      },
      "source": [
        "### Load model if exist"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y9l-3uNDxs-S",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Load existing Checkpoint or Intialize an empty model\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.python import pywrap_tensorflow\n",
        "\n",
        "load_dir = 'save/gpt2-cc-interval100-attention2048-midi'\n",
        "save_dir = 'save/gpt2-cc-interval100-attention2048-midi'\n",
        "\n",
        "def get_variables_from_checkpoint_file(file_name):\n",
        "    variables = []\n",
        "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
        "\n",
        "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
        "    for key in sorted(var_to_shape_map):\n",
        "        variables.append((key, var_to_shape_map[key]))\n",
        "\n",
        "    return variables\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "if True:\n",
        "    restore_file = tf.train.latest_checkpoint(load_dir)\n",
        "    if restore_file is not None:\n",
        "        try:\n",
        "            saver.restore(sess, restore_file)\n",
        "            print(\"Model restored.\", restore_file)\n",
        "        except:\n",
        "            saved_variables = get_variables_from_checkpoint_file(restore_file)\n",
        "            model_variables = slim.get_variables_to_restore()\n",
        "            restore_variables = []\n",
        "            for model_variable in model_variables:\n",
        "                for saved_variable_name, saved_variable_shape in saved_variables:\n",
        "                    model_variable_name = model_variable.name.split(\":\")[0]\n",
        "                    if saved_variable_name == model_variable_name and tuple(saved_variable_shape) == model_variable.shape:\n",
        "                        restore_variables.append(model_variable)\n",
        "\n",
        "            init_saver = tf.train.Saver(restore_variables)\n",
        "            init_saver.restore(sess, restore_file)\n",
        "            print(\"Model partially restored.\")\n",
        "    else:\n",
        "        print('model not exist.')\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5t6m_sMx1rB",
        "colab_type": "text"
      },
      "source": [
        "### TensorboardX Logger"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ksgK4aAx2u5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title TensorboardX Logger\n",
        "from tensorboardX import SummaryWriter\n",
        "\n",
        "class Logger(SummaryWriter):\n",
        "    def __init__(self, logdir):\n",
        "        super(Logger, self).__init__(logdir)\n",
        "\n",
        "    def log(self, log_string, value, iteration):\n",
        "            self.add_scalar(log_string, value, iteration)\n",
        "            \n",
        "logger = Logger(save_dir)            "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOHlruxmx7mJ",
        "colab_type": "text"
      },
      "source": [
        "### Train Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pRtJ8rMSyC_F",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Train the Model (From Checkpoint or Scratch). Recommended number of steps to achieve good results is 40k-60k. Do not forget to adjust this number according to the number of batches.\n",
        "log_every_steps = 1000 #@param {type:\"slider\", min:0, max:1000, step:20}\n",
        "save_every_steps = 1000 #@param {type:\"slider\", min:0, max:1000, step:20}\n",
        "number_of_batches_per_step = 4 #@param {type:\"slider\", min:0, max:32, step:1}\n",
        "learning_rate_cc = 0.001 #@param {type:\"slider\", min:0, max:0.001, step:0.000001}\n",
        "from IPython.display import clear_output\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import librosa.display\n",
        "from time import sleep\n",
        "import time\n",
        "\n",
        "batch_size = number_of_batches_per_step # Works on Google P100 GPU and Colab Pro. Otherwise, use 1 or 2. Def = 1\n",
        "log_every = log_every_steps # Display logs/plot data every indicated number of steps. Def = 10\n",
        "save_every = save_every_steps # Save the trained model (checkpoint) every indicated number of steps. Def = 10\n",
        "\n",
        "while(True):\n",
        "    for _ in range(log_every_steps):\n",
        "        _inputs = []\n",
        "        _targets = []\n",
        "        for _ in range(batch_size):\n",
        "            while(True):\n",
        "                x, y = get_data(hparams.n_time)\n",
        "                if(x.shape == y.shape):\n",
        "                    break\n",
        "                 \n",
        "            _inputs.append(x)\n",
        "            _targets.append(y)\n",
        "        _inputs = np.stack(_inputs)\n",
        "        _targets = np.stack(_targets)\n",
        "        print(_inputs.shape, _targets.shape)\n",
        "        \n",
        "        _, _global_step, _loss = sess.run([train_step, global_step, loss], \n",
        "                                          feed_dict={X: _inputs, \n",
        "                                                     Y: _targets,\n",
        "                                                     learning_rate: learning_rate_cc})\n",
        "        print(_global_step, _loss)\n",
        "        \n",
        "        if _global_step % log_every == 0:\n",
        "            logger.log('loss', _loss, _global_step)\n",
        "        \n",
        "        if _global_step % save_every == 0:\n",
        "            save_path = saver.save(sess, save_dir + '/checkpoint', global_step=_global_step)\n",
        "            print(\"Model saved in path: %s\" % save_path)\n",
        "        \n",
        "    clear_output()\n",
        "    \n",
        "    _inputs_onehot, _probs = sess.run([X_onehot, probs], feed_dict={X: _inputs})\n",
        "    \n",
        "    plt.figure(figsize=[18, 4])\n",
        "    librosa.display.specshow(_inputs_onehot[0].T)\n",
        "    plt.show()\n",
        "    \n",
        "    plt.figure(figsize=[18, 4])\n",
        "    librosa.display.specshow(_probs[0].T)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wXq-mM-TFxFF",
        "colab_type": "text"
      },
      "source": [
        "###(Optional) Save the last checkpoint/currently loaded model from memory to file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0mU0qhtlpI5",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Manual model save option from current memory\n",
        "save_path = saver.save(sess, save_dir + '/checkpoint', global_step=_global_step)\n",
        "print(\"Model saved in path: %s\" % save_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hVDIEKgB6TWR",
        "colab_type": "text"
      },
      "source": [
        "### Generate Output Sequence and save it to a MIDI file."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KwgMdlHx6sCQ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title WARNING: Created/resulting Model may produce (partially) plagiarized (overfitted) output. Excercise care and respect the copyright, please :) NOTE: Number of generated tokens MUST BE ALWAYS > Time Constant Hyperparameter of the model (i.e. if time_constant=2048, number_of_tokens_to_generate MUST BE > 2048). You can also manipulate other variables below to further improve generated output. Only the last batch is saved and displayed.\n",
        "number_of_tokens_to_generate = 1920 #@param {type:\"slider\", min:128, max:8192, step:128}\n",
        "number_of_batches = 1 #@param {type:\"slider\", min:0, max:32, step:1}\n",
        "midi_ticks_multiplier = 5 #@param {type:\"slider\", min:0, max:64, step:1}\n",
        "priming_sequence_delta = 1024 #@param {type:\"slider\", min:0, max:8192, step:64}\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "import tensorflow.contrib.slim as slim\n",
        "from tensorflow.python import pywrap_tensorflow\n",
        "\n",
        "load_dir = 'save/gpt2-cc-interval100-attention2048-midi'\n",
        "save_dir = 'save/gpt2-cc-interval100-attention2048-midi'\n",
        "\n",
        "def get_variables_from_checkpoint_file(file_name):\n",
        "    variables = []\n",
        "    reader = pywrap_tensorflow.NewCheckpointReader(file_name)\n",
        "\n",
        "    var_to_shape_map = reader.get_variable_to_shape_map()\n",
        "    for key in sorted(var_to_shape_map):\n",
        "        variables.append((key, var_to_shape_map[key]))\n",
        "\n",
        "    return variables\n",
        "\n",
        "saver = tf.train.Saver()\n",
        "\n",
        "if True:\n",
        "    restore_file = tf.train.latest_checkpoint(load_dir)\n",
        "    if restore_file is not None:\n",
        "        try:\n",
        "            saver.restore(sess, restore_file)\n",
        "            print(\"Model restored.\", restore_file)\n",
        "        except:\n",
        "            saved_variables = get_variables_from_checkpoint_file(restore_file)\n",
        "            model_variables = slim.get_variables_to_restore()\n",
        "            restore_variables = []\n",
        "            for model_variable in model_variables:\n",
        "                for saved_variable_name, saved_variable_shape in saved_variables:\n",
        "                    model_variable_name = model_variable.name.split(\":\")[0]\n",
        "                    if saved_variable_name == model_variable_name and tuple(saved_variable_shape) == model_variable.shape:\n",
        "                        restore_variables.append(model_variable)\n",
        "\n",
        "            init_saver = tf.train.Saver(restore_variables)\n",
        "            init_saver.restore(sess, restore_file)\n",
        "            print(\"Model partially restored.\")\n",
        "    else:\n",
        "        print('model not exist.')\n",
        "\n",
        "N = number_of_tokens_to_generate # Number of steps/tokens you want to generate (for). Increasing over 2000 auto-switches Collab to CPU generation which is very slow. Def = 2048\n",
        "\n",
        "x, y = get_data(hparams.n_time)\n",
        "_inputs = np.zeros([number_of_batches, N], dtype=np.int32)\n",
        "#_inputs[:(N-128), :len(x)] = x[None, :]\n",
        "_inputs[:, :len(x)] = x[None, :]\n",
        "#_inputs[:priming_sequence_delta, :len(x)] = x[None, :]\n",
        "print(_inputs)\n",
        "print('Priming Tokens Quantity: ')\n",
        "print(len(x)-priming_sequence_delta)\n",
        "\n",
        "for i in tqdm(range(N-Time)):\n",
        "\n",
        "    _sample, _prob = sess.run([sample, probs], feed_dict={X: _inputs[:, i:i+Time]})\n",
        "    _inputs[:, i+Time] = _sample \n",
        "\n",
        "print(_inputs.shape)\n",
        "\n",
        "class Event():\n",
        "    def __init__(self, time, note, cc, on, velocity):\n",
        "        self.time = time\n",
        "        self.note = note\n",
        "        self.on = on\n",
        "        self.cc = cc\n",
        "        self.velocity = velocity\n",
        "\n",
        "    def get_event_sequence(self):\n",
        "        return [self.time, self.note, int(self.on)]\n",
        "\n",
        "class Note():\n",
        "    def __init__(self):\n",
        "        self.pitch = 0\n",
        "        self.start_time = 0\n",
        "        self.end_time = 0\n",
        "\n",
        "event_list = []\n",
        "time = 0\n",
        "event = None\n",
        "\n",
        "EventDim = IntervalDim + VelocityDim + NoteOnDim + NoteOffDim # 388\n",
        "\n",
        "for _input in _inputs[0][priming_sequence_delta:]:\n",
        "    # interval\n",
        "    if _input < IntervalDim: \n",
        "        time += _input\n",
        "        event = Event(time, 0, False, 0, 0)\n",
        "\n",
        "    # velocity\n",
        "    elif _input < NoteOnOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.velocity = (_input - VelocityOffset) / VelocityDim * 128\n",
        "        #print('velocity : ', event.velocity)\n",
        "\n",
        "    # note on\n",
        "    elif _input < NoteOffOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "\n",
        "        event.note = _input - NoteOnOffset\n",
        "        event.on = True\n",
        "        event_list.append(event)\n",
        "        #event_list.append(Event(event.time + 100, event.note, False))\n",
        "        event = None\n",
        "\n",
        "    # note off\n",
        "    elif _input < CCOffset:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.note = _input - NoteOffOffset\n",
        "        event.on = False\n",
        "        event_list.append(event)\n",
        "        event = None\n",
        "\n",
        "    ## CC\n",
        "    else:\n",
        "        if event is None:\n",
        "            continue\n",
        "        event.cc = True\n",
        "        on = _input - CCOffset == 1\n",
        "        event.on = on\n",
        "        #print(on)\n",
        "        event_list.append(event)\n",
        "        event = None\n",
        "\n",
        "import midi\n",
        "# Instantiate a MIDI Pattern (contains a list of tracks)\n",
        "pattern = midi.Pattern()\n",
        "# Instantiate a MIDI Track (contains a list of MIDI events)\n",
        "track = midi.Track()\n",
        "# Append the track to the pattern\n",
        "pattern.append(track)\n",
        "\n",
        "prev_time = 0\n",
        "pitches = [None for _ in range(128)]\n",
        "for event in event_list:\n",
        "    tick = (event.time - prev_time) * midi_ticks_multiplier\n",
        "    prev_time = event.time\n",
        "\n",
        "    # case NOTE:\n",
        "    if not event.cc:\n",
        "        if event.on:\n",
        "            if pitches[event.note] is not None:\n",
        "                # Instantiate a MIDI note off event, append it to the track\n",
        "                off = midi.NoteOffEvent(tick=0, pitch=event.note)\n",
        "                track.append(off)\n",
        "                pitches[event.note] = None\n",
        "\n",
        "            # Instantiate a MIDI note on event, append it to the track\n",
        "            on = midi.NoteOnEvent(tick=tick, velocity=int(event.velocity), pitch=event.note)\n",
        "            track.append(on)\n",
        "            pitches[event.note] = prev_time\n",
        "        else:\n",
        "            # Instantiate a MIDI note off event, append it to the track\n",
        "            off = midi.NoteOffEvent(tick=tick, pitch=event.note)\n",
        "            track.append(off)\n",
        "            pitches[event.note] = None\n",
        "\n",
        "    # case CC:\n",
        "    elif event.cc:\n",
        "        if event.on:\n",
        "            cc = midi.ControlChangeEvent(tick=tick, control=64, value=64)\n",
        "        else:\n",
        "            cc = midi.ControlChangeEvent(tick=tick, control=64, value=0)\n",
        "\n",
        "        track.append(cc)\n",
        "\n",
        "    for pitch in range(128):\n",
        "        if pitches[pitch] is not None and pitches[pitch] + 100 < prev_time:\n",
        "            #print('here')\n",
        "            off = midi.NoteOffEvent(tick=0, pitch=pitch)\n",
        "            track.append(off)\n",
        "            pitches[pitch] = None\n",
        "\n",
        "\n",
        "# Add the end of track event, append it to the track\n",
        "eot = midi.EndOfTrackEvent(tick=1)\n",
        "track.append(eot)\n",
        "# Print out the pattern\n",
        "#print(pattern)\n",
        "# Save the pattern to disk\n",
        "midi.write_midifile(\"output_file.mid\", pattern)\n",
        "\n",
        "print('Successfully exported the output to output_file.mid')\n",
        "print('Downloading output_file.mid')\n",
        "from google.colab import files\n",
        "files.download('/content/output_file.mid')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SjeD4JOXAhqG",
        "colab_type": "text"
      },
      "source": [
        "# III. Plot and Graph the Output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LiFahumhwqtZ",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Plot and Graph the Output :)\n",
        "graphs_length_inches = 18 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "notes_graph_height = 6 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "rendered_wav_graph_height = 3 #@param {type:\"slider\", min:0, max:20, step:1}\n",
        "import librosa\n",
        "import numpy as np\n",
        "import pretty_midi\n",
        "import pypianoroll\n",
        "from pypianoroll import Multitrack, Track\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "#matplotlib.use('SVG')\n",
        "# For plotting\n",
        "import mir_eval.display\n",
        "import librosa.display\n",
        "%matplotlib inline\n",
        "\n",
        "\n",
        "midi_data = pretty_midi.PrettyMIDI('/content/output_file.mid')\n",
        "\n",
        "def plot_piano_roll(pm, start_pitch, end_pitch, fs=100):\n",
        "    # Use librosa's specshow function for displaying the piano roll\n",
        "    librosa.display.specshow(pm.get_piano_roll(fs)[start_pitch:end_pitch],\n",
        "                             hop_length=1, sr=fs, x_axis='time', y_axis='cqt_note',\n",
        "                             fmin=pretty_midi.note_number_to_hz(start_pitch))\n",
        "\n",
        "\n",
        "\n",
        "roll = np.zeros([int(graphs_length_inches), 128])\n",
        "# Plot the output\n",
        "\n",
        "track = Multitrack('/content/output_file.mid', name='track')\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "fig, ax = track.plot()\n",
        "fig.set_size_inches(graphs_length_inches, notes_graph_height)\n",
        "plt.figure(figsize=[graphs_length_inches, notes_graph_height])\n",
        "ax2 = plot_piano_roll(midi_data, 24, 84)\n",
        "plt.show(block=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqMikmVMtTwh",
        "colab_type": "text"
      },
      "source": [
        "###Save your model to your Google Drive directly as it is very fast :)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GcrTq7tmC97p",
        "colab_type": "code",
        "cellView": "form",
        "colab": {}
      },
      "source": [
        "#@title Standard Google Drive connect code\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}